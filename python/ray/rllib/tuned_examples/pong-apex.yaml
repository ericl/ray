pong-apex:
    env: Pong-v0
    run: DQN
    resources:
        cpu:
            eval: spec.config.num_workers
        gpu: 1
        driver_cpu_limit: 1
        driver_gpu_limit: 1
    stop:
        episode_reward_mean: 20
    config:
        num_workers: 4
        n_step: 3
        gamma: 0.99
        rmsprop: False
        learning_starts: 1000
        buffer_size: 10000
        target_network_update_freq: 500000
        sample_batch_size: 50
        max_weight_sync_delay: 400
        train_batch_size: 512
        apex_optimizer: True
        timesteps_per_iteration: 25000
        per_worker_exploration: True
        worker_side_prioritization: True
        num_replay_buffer_shards: 4
        model:
          grayscale: True
